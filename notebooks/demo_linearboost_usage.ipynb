{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from linearboost.linear_boost import LinearBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (3.0.2)\n",
      "Requirement already satisfied: lightgbm in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (4.6.0)\n",
      "Requirement already satisfied: catboost in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (1.2.8)\n",
      "Requirement already satisfied: numpy in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from xgboost) (2.2.6)\n",
      "Requirement already satisfied: scipy in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from xgboost) (1.15.3)\n",
      "Requirement already satisfied: graphviz in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from catboost) (3.10.3)\n",
      "Requirement already satisfied: pandas>=0.24 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from catboost) (2.3.1)\n",
      "Requirement already satisfied: plotly in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from catboost) (6.2.0)\n",
      "Requirement already satisfied: six in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from matplotlib->catboost) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Users/hamidrezakeshavarz/Documents/GitHub/linearboost-classifier/.venv/lib/python3.13/site-packages (from plotly->catboost) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# The Huberman's Survival's id on UCI Machine Learning Repository\n",
    "dataset_id = 43\n",
    "\n",
    "dataset = fetch_ucirepo(id=dataset_id) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = dataset.data.features.copy()\n",
    "y = dataset.data.targets\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y = label_encoder.fit_transform(y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Convert categorical columns to 'category' dtype\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "# Handle missing values\n",
    "# Fill numeric columns with median\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# Fill categorical columns with mode\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].fillna(X[col].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*ignore_implicit_zeros.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*n_quantiles.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LinearBoost results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 20:32:30,509] A new study created in memory with name: no-name-39689138-b2a1-447a-af63-be7733a7aeb8\n",
      "[I 2025-07-28 20:32:30,764] Trial 0 finished with value: 0.7283291353857195 and parameters: {'n_estimators': 256, 'learning_rate': 0.11807746849928968, 'algorithm': 'SAMME', 'scaler': 'minmax', 'kernel': 'rbf', 'gamma': 0.10360685199357951}. Best is trial 0 with value: 0.7283291353857195.\n",
      "[I 2025-07-28 20:32:32,767] Trial 1 finished with value: 0.7323671972329208 and parameters: {'n_estimators': 363, 'learning_rate': 0.013883181171194234, 'algorithm': 'SAMME', 'scaler': 'robust', 'kernel': 'rbf', 'gamma': 0.3980809182349502}. Best is trial 1 with value: 0.7323671972329208.\n",
      "...",
      "[I 2025-07-28 20:34:42,444] Trial 199 finished with value: 0.7515000210035615 and parameters: {'n_estimators': 245, 'learning_rate': 0.06109405565734974, 'algorithm': 'SAMME', 'scaler': 'minmax', 'kernel': 'rbf', 'gamma': 0.08461411124525335}. Best is trial 167 with value: 0.7583125868901313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "F1 Score: 0.7583125868901313\n",
      "Parameters: \n",
      "n_estimators: 384\n",
      "learning_rate: 0.06667610599938725\n",
      "algorithm: SAMME\n",
      "scaler: robust\n",
      "kernel: rbf\n",
      "gamma: 0.002777056559327566\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "def custom_loss(y_true, y_pred, weights):\n",
    "    return np.mean(weights * (y_true - y_pred) ** 2)\n",
    "\n",
    "df = X\n",
    "\n",
    "# One-hot encoding\n",
    "cat_features = list(df.select_dtypes(include=['object', 'category']).columns)\n",
    "for col in cat_features:\n",
    "    df_onehot = pd.get_dummies(df[col], prefix=col)\n",
    "    df = df.drop(col, axis=1)\n",
    "    df = pd.concat([df_onehot, df], axis=1)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
    "        'algorithm': trial.suggest_categorical('algorithm', ['SAMME', 'SAMME.R']),\n",
    "        'scaler': trial.suggest_categorical('scaler', [\n",
    "            'minmax', 'robust', 'quantile-uniform', 'quantile-normal'\n",
    "        ]),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly', 'sigmoid']),\n",
    "    }\n",
    "\n",
    "    if params['kernel'] != 'linear':\n",
    "        params['gamma'] = trial.suggest_float('gamma', 1e-3, 10.0, log=True)\n",
    "    if params['kernel'] == 'poly':\n",
    "        params['degree'] = trial.suggest_int('degree', 2, 5)\n",
    "    if params['kernel'] in ['poly', 'sigmoid']:\n",
    "        params['coef0'] = trial.suggest_float('coef0', 0.0, 1.0)\n",
    "    \n",
    "    # Using a custom loss function here\n",
    "    #params['loss_function'] = custom_loss\n",
    "\n",
    "    model = LinearBoostClassifier(**params)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        estimator=model,\n",
    "        X=df,\n",
    "        y=y,\n",
    "        scoring='f1_weighted',\n",
    "        cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Display the best trial's results\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f'F1 Score: {trial.value}')\n",
    "print('Parameters: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 20:34:58,357] A new study created in memory with name: no-name-fd2e9753-4f61-49f9-a22c-28b4c0177247\n",
      "[I 2025-07-28 20:34:59,157] Trial 0 finished with value: 0.653658178784821 and parameters: {'n_estimators': 122, 'max_depth': 18, 'learning_rate': 0.6638400324564625, 'gamma': 1.3755330590290604e-05, 'min_child_weight': 6, 'subsample': 0.5447494156166959, 'colsample_bytree': 0.8879793066877644, 'reg_alpha': 1.0163427568069608e-07, 'reg_lambda': 2.39079916775675e-06}. Best is trial 0 with value: 0.653658178784821.\n",
      "[I 2025-07-28 20:34:59,681] Trial 1 finished with value: 0.6770776702365993 and parameters: {'n_estimators': 317, 'max_depth': 20, 'learning_rate': 0.13249519981914618, 'gamma': 1.5953454630407348e-08, 'min_child_weight': 8, 'subsample': 0.9709077195029082, 'colsample_bytree': 0.9624785240081783, 'reg_alpha': 2.203094364625466e-07, 'reg_lambda': 1.4395372969777643e-08}. Best is trial 1 with value: 0.6770776702365993.\n",
      "...",
      "[I 2025-07-28 20:35:10,555] Trial 199 finished with value: 0.716699568607657 and parameters: {'n_estimators': 736, 'max_depth': 14, 'learning_rate': 0.5430003212800782, 'gamma': 0.00012981585330188922, 'min_child_weight': 7, 'subsample': 0.988996549758597, 'colsample_bytree': 0.5778156428539348, 'reg_alpha': 0.0012464630655151046, 'reg_lambda': 0.00018326860521084625}. Best is trial 22 with value: 0.7218094394645215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "F1 Score: 0.721809\n",
      "Parameters:\n",
      "n_estimators: 395\n",
      "max_depth: 14\n",
      "learning_rate: 0.5516744736853054\n",
      "gamma: 0.06586236308160907\n",
      "min_child_weight: 7\n",
      "subsample: 0.934260221749137\n",
      "colsample_bytree: 0.5657192375418623\n",
      "reg_alpha: 0.0004839456623687217\n",
      "reg_lambda: 0.024086595827121155\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'use_label_encoder': False,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 20, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.7),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "        'enable_categorical': True,\n",
    "        'eval_metric': 'logloss',\n",
    "        'verbosity': 0\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        estimator=model,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        scoring='f1_weighted',\n",
    "        cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print('Best trial:')\n",
    "print(f'F1 Score: {best_trial.value:.6f}')\n",
    "print('Parameters:')\n",
    "for k, v in best_trial.params.items():\n",
    "    print(f'{k}: {v}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 20:39:17,046] A new study created in memory with name: no-name-d640d2f2-b93d-4408-a7ea-9161e95491e3\n",
      "[I 2025-07-28 20:39:17,550] Trial 0 finished with value: 0.6231313020966095 and parameters: {'boosting_type': 'goss', 'num_leaves': 157, 'learning_rate': 0.011930732887702704, 'n_estimators': 104, 'max_depth': 8, 'min_child_samples': 71, 'subsample': 0.9402086280771477, 'colsample_bytree': 0.7682647640164344, 'reg_alpha': 1.4241168044547617e-08, 'reg_lambda': 2.0676712941542342e-07, 'min_split_gain': 0.0033415036895292826, 'cat_smooth': 97, 'cat_l2': 0.6970465070605171}. Best is trial 0 with value: 0.6231313020966095.\n",
      "[I 2025-07-28 20:39:32,638] Trial 1 finished with value: 0.6231313020966095 and parameters: {'boosting_type': 'dart', 'num_leaves': 175, 'learning_rate': 0.0023119406442152646, 'n_estimators': 824, 'max_depth': 8, 'min_child_samples': 45, 'subsample': 0.9676678537059415, 'colsample_bytree': 0.5552007172897914, 'reg_alpha': 2.556389565074754e-07, 'reg_lambda': 1.8954788415197908e-06, 'min_split_gain': 9.567889959044472e-08, 'cat_smooth': 8, 'cat_l2': 0.012629197180178365}. Best is trial 0 with value: 0.6231313020966095.\n",
      "...",
      "[I 2025-07-28 21:09:32,868] Trial 199 finished with value: 0.7127633201595156 and parameters: {'boosting_type': 'dart', 'num_leaves': 144, 'learning_rate': 0.012575812659743247, 'n_estimators': 549, 'max_depth': 11, 'min_child_samples': 33, 'subsample': 0.8201396579082235, 'colsample_bytree': 0.8618094826946774, 'reg_alpha': 0.00022277139513162425, 'reg_lambda': 1.2026457556920858, 'min_split_gain': 9.340322067132456e-08, 'cat_smooth': 78, 'cat_l2': 9.351735111010793}. Best is trial 137 with value: 0.7338329002847149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "F1 Score: 0.733833\n",
      "Parameters:\n",
      "boosting_type: dart\n",
      "num_leaves: 115\n",
      "learning_rate: 0.014925187890769775\n",
      "n_estimators: 440\n",
      "max_depth: 18\n",
      "min_child_samples: 25\n",
      "subsample: 0.8388698484023127\n",
      "colsample_bytree: 0.871735744058394\n",
      "reg_alpha: 0.0002339943750255717\n",
      "reg_lambda: 0.008719224583360354\n",
      "min_split_gain: 6.975191054445815e-05\n",
      "cat_smooth: 52\n",
      "cat_l2: 1.870771829368486e-07\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss']),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 20, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 1e-8, 1.0, log=True),\n",
    "        'cat_smooth': trial.suggest_int('cat_smooth', 1, 100),\n",
    "        'cat_l2': trial.suggest_float('cat_l2', 1e-8, 10.0, log=True),\n",
    "        'verbosity': -1\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        estimator=model,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        scoring='f1_weighted',\n",
    "        cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print('Best trial:')\n",
    "print(f'F1 Score: {best_trial.value:.6f}')\n",
    "print('Parameters:')\n",
    "for k, v in best_trial.params.items():\n",
    "    print(f'{k}: {v}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 21:10:05,884] A new study created in memory with name: no-name-bf4ade11-fdd4-4e51-8e36-3ce62bb0ef30\n",
      "[I 2025-07-28 21:10:06,304] Trial 0 finished with value: 0.644865039962623 and parameters: {'iterations': 326, 'depth': 10, 'learning_rate': 0.19634246718523193, 'l2_leaf_reg': 2.874223428781629e-05, 'random_strength': 0.0007132910532975053, 'bagging_temperature': 4.68236671244208, 'border_count': 140, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 71, 'rsm': 0.851641906909135}. Best is trial 0 with value: 0.644865039962623.\n",
      "[I 2025-07-28 21:10:06,587] Trial 1 finished with value: 0.6769947086440917 and parameters: {'iterations': 364, 'depth': 13, 'learning_rate': 0.04465629029593174, 'l2_leaf_reg': 1.3554273893773743e-08, 'random_strength': 0.4601972154575927, 'bagging_temperature': 1.856284401555177, 'border_count': 182, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 33, 'rsm': 0.27841739352654576}. Best is trial 1 with value: 0.6769947086440917.\n",
      "...",
      "[I 2025-07-28 21:10:22,377] Trial 199 finished with value: 0.713373121188903 and parameters: {'iterations': 161, 'depth': 2, 'learning_rate': 0.007216156705027904, 'l2_leaf_reg': 4.2665020699161245e-07, 'random_strength': 0.00017324894641089118, 'bagging_temperature': 0.4153387841633685, 'border_count': 96, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 96, 'rsm': 0.8596971617051177}. Best is trial 94 with value: 0.7319447527560347.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "F1 Score: 0.731945\n",
      "Parameters:\n",
      "iterations: 168\n",
      "depth: 5\n",
      "learning_rate: 0.00889070096045054\n",
      "l2_leaf_reg: 3.173038372914875e-05\n",
      "random_strength: 0.0004606096176348796\n",
      "bagging_temperature: 0.9387985722566684\n",
      "border_count: 56\n",
      "grow_policy: Depthwise\n",
      "min_data_in_leaf: 92\n",
      "rsm: 0.7489477360324039\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 500),\n",
    "        'depth': trial.suggest_int('depth', 1, 16),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.5, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.1, 10.0, log=True),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
    "        'rsm': trial.suggest_float('rsm', 0.1, 1.0),\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'F1',\n",
    "        'cat_features': categorical_cols,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        estimator=model,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        scoring='f1_weighted',\n",
    "        cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print('Best trial:')\n",
    "print(f'F1 Score: {best_trial.value:.6f}')\n",
    "print('Parameters:')\n",
    "for k, v in best_trial.params.items():\n",
    "    print(f'{k}: {v}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
